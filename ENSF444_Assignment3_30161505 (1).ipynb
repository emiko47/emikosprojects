{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "CNDKREiQRJJX",
   "metadata": {
    "id": "CNDKREiQRJJX"
   },
   "source": [
    "<font size=\"+3\"><b>Assignment 3: Non-Linear Models and Validation Metrics</b></font>\n",
    "\n",
    "***\n",
    "* **Full Name** =\n",
    "* **UCID** =\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {
    "id": "ce31b39a"
   },
   "source": [
    "<font color='Blue'>\n",
    "In this assignment, you will need to write code that uses non-linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment.\n",
    "</font>\n",
    "\n",
    "|                **Question**                | **Point** |\n",
    "|:------------------------------------------:|:---------:|\n",
    "|           **Part 1: Regression**           |  **14.5** |\n",
    "|          Step 0: Import Libraries          |           |\n",
    "|             Step 1: Data Input             |    0.5    |\n",
    "|           Step 2: Data Processing          |     0     |\n",
    "| Step 3: Implement   Machine Learning Model |    0.5    |\n",
    "|           Step 4: Validate Model           |    0.5    |\n",
    "|         Step 5: Visualize   Results        |     3     |\n",
    "|                  Questions                 |     6     |\n",
    "|             Process Description            |     4     |\n",
    "|         **Part 2: Classification**         |  **17.5** |\n",
    "|             Step 1: Data Input             |     2     |\n",
    "|           Step 2: Data Processing          |    1.5    |\n",
    "| Step 3: Implement   Machine Learning Model |           |\n",
    "|            Step 4: Validate Mode           |           |\n",
    "|         Step 5: Visualize   Results        |     4     |\n",
    "|                  Questions                 |     6     |\n",
    "|             Process Description            |     4     |\n",
    "|   **Part 3: Observations/Interpretation**  |   **3**   |\n",
    "|           **Part 4: Reflection**           |   **2**   |\n",
    "|                  **Total**                 |   **37**  |\n",
    "|                                            |           |\n",
    "|                  **Bonus**                 |           |\n",
    "|         **Part 5: Bonus Question**         |   **3**   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf275ca7",
   "metadata": {
    "id": "cf275ca7"
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b67a661",
   "metadata": {
    "id": "2b67a661"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2d2c3",
   "metadata": {
    "id": "5ee2d2c3"
   },
   "source": [
    "# **Part 1: Regression (14.5 marks)**\n",
    "\n",
    "For this section, we will be continuing with the concrete example from yellowbrick. You will need to compare these results to the results from the previous assignment. Please use the results from the solution if you were unable to complete Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219f163",
   "metadata": {
    "id": "8219f163"
   },
   "source": [
    "## **Step 1:** Data Input (0.5 marks)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library:\n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the concrete dataset into the feature matrix `X` and target vector `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2af8bd32",
   "metadata": {
    "id": "2af8bd32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X size: 8240\n",
      "y size: 1030\n",
      "X type: <class 'pandas.core.frame.DataFrame'>\n",
      "y type: <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import concrete dataset from yellowbrick library\n",
    "from yellowbrick.datasets import load_concrete\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X, y = load_concrete()\n",
    "\n",
    "print(\"X size:\", X.size)\n",
    "print(\"y size:\", y.size)\n",
    "print(\"X type:\", type(X))\n",
    "print(\"y type:\", type(y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fea4cc",
   "metadata": {
    "id": "42fea4cc"
   },
   "source": [
    "## **Step 2:** Data Processing (0 marks)\n",
    "\n",
    "Data processing was completed in the previous assignment. No need to repeat here.\n",
    "\n",
    "<font color='red'>\n",
    "This is just for your information and no action is required from you for this step.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a245d00",
   "metadata": {
    "id": "2a245d00"
   },
   "source": [
    "## **Step 3:** Implement Machine Learning Model (0.5 marks)\n",
    "\n",
    "1. Import the Decision Tree, Random Forest and Gradient Boosting Machines regression models from sklearn\n",
    "2. Instantiate the three models with `max_depth = 5`. Are there any other parameters that you will need to set?\n",
    "3. Implement each machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f994e31",
   "metadata": {
    "id": "3f994e31"
   },
   "source": [
    "## **Step 4:** Validate Model (0.5 marks)\n",
    "\n",
    "Calculate the average training and validation accuracy using mean squared error with cross-validation. To do this, you will need to set `scoring='neg_mean_squared_error'` in your `cross_validate` function and negate the results (multiply by -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3f7a8",
   "metadata": {
    "id": "5fc3f7a8"
   },
   "source": [
    "## **Step 5:** Visualize Results (3 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: DT, RF and GB\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdc93a78",
   "metadata": {
    "id": "fdc93a78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree:\n",
      "Average Training MSE: 47.91856102734339\n",
      "Average Validation MSE: 163.08777547307804\n",
      "\n",
      "Random Forest:\n",
      "Average Training MSE: 32.05543206759723\n",
      "Average Validation MSE: 156.40497179627897\n",
      "\n",
      "Gradient Boosting:\n",
      "Average Training MSE: 3.739270010942101\n",
      "Average Validation MSE: 99.3602591572192\n",
      "\n",
      "    Training MSE  Validation MSE\n",
      "DT     47.918561      163.087775\n",
      "RF     32.055432      156.404972\n",
      "GB      3.739270       99.360259\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "dtregressor = DecisionTreeRegressor(max_depth=5, random_state = 0)#from sci-kit learn\n",
    "#for the random forest and gradient boosting regressors, we need to specify the number of trees to use(n_estimators)\n",
    "rfregressor = RandomForestRegressor(n_estimators = 100, random_state = 0, max_depth = 5)\n",
    "gbregressor = GradientBoostingRegressor(max_depth = 5, random_state = 0, n_estimators = 100, learning_rate = 0.1)\n",
    "\n",
    "dtregressor.fit(X, y)\n",
    "rfregressor.fit(X, y)\n",
    "gbregressor.fit(X,y)\n",
    "\n",
    "\n",
    "# Cross-validate Decision Tree Regressor\n",
    "dt_scores = cross_validate(dtregressor, X, y, scoring='neg_mean_squared_error', cv=5, return_train_score=True)\n",
    "dt_train_mse = -1 * dt_scores['train_score']\n",
    "dt_val_mse = -1 * dt_scores['test_score']\n",
    "\n",
    "# Cross-validate Random Forest Regressor\n",
    "rf_scores = cross_validate(rfregressor, X, y, scoring='neg_mean_squared_error', cv=5, return_train_score=True)\n",
    "rf_train_mse = -1 * rf_scores['train_score']\n",
    "rf_val_mse = -1 * rf_scores['test_score']\n",
    "\n",
    "# Cross-validate Gradient Boosting Regressor\n",
    "gb_scores = cross_validate(gbregressor, X, y, scoring='neg_mean_squared_error', cv=5, return_train_score=True)\n",
    "gb_train_mse = -1 * gb_scores['train_score']\n",
    "gb_val_mse = -1 * gb_scores['test_score']\n",
    "\n",
    "# Calculate average training and validation MSE\n",
    "avg_dt_train_mse = np.mean(dt_train_mse)\n",
    "avg_dt_val_mse = np.mean(dt_val_mse)\n",
    "\n",
    "avg_rf_train_mse = np.mean(rf_train_mse)\n",
    "avg_rf_val_mse = np.mean(rf_val_mse)\n",
    "\n",
    "avg_gb_train_mse = np.mean(gb_train_mse)\n",
    "avg_gb_val_mse = np.mean(gb_val_mse)\n",
    "\n",
    "print(\"Decision Tree:\")\n",
    "print(f\"Average Training MSE: {avg_dt_train_mse}\")\n",
    "print(f\"Average Validation MSE: {avg_dt_val_mse}\\n\")\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "print(f\"Average Training MSE: {avg_rf_train_mse}\")\n",
    "print(f\"Average Validation MSE: {avg_rf_val_mse}\\n\")\n",
    "\n",
    "print(\"Gradient Boosting:\")\n",
    "print(f\"Average Training MSE: {avg_gb_train_mse}\")\n",
    "print(f\"Average Validation MSE: {avg_gb_val_mse}\\n\")\n",
    "\n",
    "#chat gpt used here. In the process description remember to include the prompts and explain thought process\n",
    "#here, I think a higher MSE indicates better performance in this case, since we used \"scoring = neg_mean_squared_error\"\n",
    "\n",
    "results_data = {\n",
    "    'Training MSE': [47.91856102734339, 32.05543206759723, 3.739270010942101],\n",
    "    'Validation MSE': [163.08777547307804, 156.40497179627897, 99.3602591572192]\n",
    "}\n",
    "\n",
    "index = ['DT', 'RF', 'GB']\n",
    "results_df = pd.DataFrame(results_data, index=index)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31715a9d",
   "metadata": {
    "id": "31715a9d"
   },
   "source": [
    "Repeat the step above to print the R2 score instead of the mean-squared error. For this case, you can use `scoring='r2'`.\n",
    "\n",
    "<font color='red'>\n",
    "Due to the similarity of this to the main part of step 5, this part is 0.5 and the main part of step 5 is 2.5 of the total 3 points for this step.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83539f47",
   "metadata": {
    "id": "83539f47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree:\n",
      "Average Training MSE: 0.8228872809524459\n",
      "Average Validation MSE: 0.1762104452178903\n",
      "\n",
      "Random Forest:\n",
      "Average Training MSE: 0.881221342371458\n",
      "Average Validation MSE: 0.1737480262274312\n",
      "\n",
      "Gradient Boosting:\n",
      "Average Training MSE: 0.9864362663137645\n",
      "Average Validation MSE: 0.4737008698990578\n",
      "\n",
      "    Training MSE  Validation MSE\n",
      "DT      0.822887        0.176210\n",
      "RF      0.881221        0.173748\n",
      "GB      0.986436        0.473701\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# This would be similar to the main step, the main difference is the scoring.\n",
    "dt_scores = cross_validate(dtregressor, X, y, scoring='r2', cv=5, return_train_score=True)\n",
    "dt_train_mse = dt_scores['train_score']\n",
    "dt_val_mse = dt_scores['test_score']\n",
    "\n",
    "# Cross-validate Random Forest Regressor\n",
    "rf_scores = cross_validate(rfregressor, X, y, scoring='r2', cv=5, return_train_score=True)\n",
    "rf_train_mse = rf_scores['train_score']\n",
    "rf_val_mse = rf_scores['test_score']\n",
    "\n",
    "# Cross-validate Gradient Boosting Regressor\n",
    "gb_scores = cross_validate(gbregressor, X, y, scoring='r2', cv=5, return_train_score=True)\n",
    "gb_train_mse = gb_scores['train_score']\n",
    "gb_val_mse = gb_scores['test_score']\n",
    "\n",
    "# Calculate average training and validation MSE\n",
    "avg_dt_train_mse = np.mean(dt_train_mse)\n",
    "avg_dt_val_mse = np.mean(dt_val_mse)\n",
    "\n",
    "avg_rf_train_mse = np.mean(rf_train_mse)\n",
    "avg_rf_val_mse = np.mean(rf_val_mse)\n",
    "\n",
    "avg_gb_train_mse = np.mean(gb_train_mse)\n",
    "avg_gb_val_mse = np.mean(gb_val_mse)\n",
    "\n",
    "print(\"Decision Tree:\")\n",
    "print(f\"Average Training MSE: {avg_dt_train_mse}\")\n",
    "print(f\"Average Validation MSE: {avg_dt_val_mse}\\n\")\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "print(f\"Average Training MSE: {avg_rf_train_mse}\")\n",
    "print(f\"Average Validation MSE: {avg_rf_val_mse}\\n\")\n",
    "\n",
    "print(\"Gradient Boosting:\")\n",
    "print(f\"Average Training MSE: {avg_gb_train_mse}\")\n",
    "print(f\"Average Validation MSE: {avg_gb_val_mse}\\n\")\n",
    "\n",
    "#chat gpt used here. In the process description remember to include the prompts and explain thought process\n",
    "#here, I think a higher MSE indicates better performance in this case, since we used \"scoring = neg_mean_squared_error\"\n",
    "\n",
    "results_data = {\n",
    "    'Training MSE': [0.8228872809524459, 0.881221342371458, 0.9864362663137645],\n",
    "    'Validation MSE': [0.1762104452178903, 0.1737480262274312, 0.4737008698990578]\n",
    "}\n",
    "\n",
    "index = ['DT', 'RF', 'GB']\n",
    "results_df = pd.DataFrame(results_data, index=index)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5257a98",
   "metadata": {
    "id": "a5257a98"
   },
   "source": [
    "## Questions (6 marks)\n",
    "1. How do these results compare to the results using a linear model in the previous assignment? Use values.\n",
    "1. Out of the models you tested, which model would you select for this dataset and why?\n",
    "1. If you wanted to increase the accuracy of the tree-based models, what would you do? Provide two suggestions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2PRnpiFjVDzv",
   "metadata": {
    "id": "2PRnpiFjVDzv"
   },
   "source": [
    "# <font color='Green'><b>\n",
    "    \n",
    "1. In the previous assignment, we got a mean square error above 100 for both training and validation accuracy(114.6 and 106.8 to be exact; meaning that our predicted values were far off from the actual labels. For the models above, since we specified the scoring parameter as \"neg_mean_squared_error\", a high MSE would indicate better performance in this case. While the models above had a better performance with the training set, they performed rather poorly with the validation set, with low validation MSEs of 0.18, 0.17 and 0.47(Decision Tree, Random Forest, and Gradient Boosting respectively)\n",
    "    \n",
    "2. For this dataset, I would select the Gradient Boosting model simply because it has the highest training and validation accuracy.\n",
    "    \n",
    "3. Firstly, I would limit the value of the max_depth to prevent overfitting. I would probably also increase the learning rate so that the model tries to correct its errors more strongly.\n",
    "    \n",
    "    </b></font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b238f4",
   "metadata": {
    "id": "37b238f4"
   },
   "source": [
    "## Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93097bfe",
   "metadata": {
    "id": "93097bfe"
   },
   "source": [
    "<font color='Green'><b>\n",
    "    \n",
    "1. I sourced all imports from scikit-learn.org. The code for computing the cross-validation, train_mse's, val_mse's and the average mse's were all sourced from chatgpt.\n",
    "    \n",
    "2. I completed the steps in the order they were given.\n",
    "    \n",
    "3. Prompt 1: How can I calculate the average training and validation accuracy using mean squared error with cross-validation? Explain how I can do this while setting the scoring parameter as 'neg_mean_squared_error' and negating the results.\n",
    "    \n",
    "I couldn't find anything useful for this step in the lecture notes so I put prompt 1 into chatgpt to get an idea of where to get started. Then I modified the code for all three models.\n",
    "    \n",
    "Prompt 2: Explain what happens when the scoring parameter is set to 'neg_mean_squared_error'.\n",
    "    \n",
    "I didn't know how 'neg_mean_squared_error' affected the MSE so I passed prompt 2 to chatgpt and figured out that a higher MSE in this case would indicate better performance.\n",
    "    \n",
    "4. I guess my only challenge was not necessarily knowing where to get started but I was able to break through with the help of chatgpt.\n",
    "    \n",
    "    \n",
    "</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {
    "id": "f7c6de86"
   },
   "source": [
    "# **Part 2: Classification (17.5 marks)**\n",
    "\n",
    "You have been asked to develop code that can help the user classify different wine samples. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {
    "id": "5f9d33a8"
   },
   "source": [
    "## **Step 1:** Data Input (2 marks)\n",
    "\n",
    "The data used for this task can be downloaded from UCI: https://archive.ics.uci.edu/dataset/109/wine\n",
    "\n",
    "Use the pandas library to load the dataset. You must define the column headers if they are not included in the dataset\n",
    "\n",
    "You will need to split the dataset into feature matrix `X` and target vector `y`. Which column represents the target vector?\n",
    "\n",
    "Print the size and type of `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33583c67",
   "metadata": {
    "id": "33583c67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X size: 2314\n",
      "y size: 178\n",
      "X type: <class 'pandas.core.frame.DataFrame'>\n",
      "y type: <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import wine dataset\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "wine = fetch_ucirepo(id=109) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = wine.data.features \n",
    "y = wine.data.targets \n",
    "\n",
    "print(\"X size:\", X.size)\n",
    "print(\"y size:\", y.size)\n",
    "print(\"X type:\", type(X))\n",
    "print(\"y type:\", type(y))\n",
    "print(\"The first and only column of y represents the target vector\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {
    "id": "156db208"
   },
   "source": [
    "## **Step 2:** Data Processing (1.5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28af110",
   "metadata": {
    "id": "a28af110"
   },
   "source": [
    "Print the first five rows of the dataset to inspect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea266921",
   "metadata": {
    "id": "ea266921"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malicacid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity_of_ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>0D280_0D315_of_diluted_wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alcohol  Malicacid   Ash  Alcalinity_of_ash  Magnesium  Total_phenols  \\\n",
       "0    14.23       1.71  2.43               15.6        127           2.80   \n",
       "1    13.20       1.78  2.14               11.2        100           2.65   \n",
       "2    13.16       2.36  2.67               18.6        101           2.80   \n",
       "3    14.37       1.95  2.50               16.8        113           3.85   \n",
       "4    13.24       2.59  2.87               21.0        118           2.80   \n",
       "\n",
       "   Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity   Hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   0D280_0D315_of_diluted_wines  Proline  \n",
       "0                          3.92     1065  \n",
       "1                          3.40     1050  \n",
       "2                          3.17     1185  \n",
       "3                          3.45     1480  \n",
       "4                          2.93      735  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834fc8fe",
   "metadata": {
    "id": "834fc8fe"
   },
   "source": [
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97c6e9dc",
   "metadata": {
    "id": "97c6e9dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "missing_values = X.isnull().sum().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070956af",
   "metadata": {
    "id": "070956af"
   },
   "source": [
    "How many samples do we have of each type of wine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b37a6fd9",
   "metadata": {
    "id": "b37a6fd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "2    71\n",
      "1    59\n",
      "3    48\n",
      "Name: count, dtype: int64\n",
      "So wine 1 has 59 samples, wine 2 has 71 samples, and wine 3 has 48 samples\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "#process description: since there are 3 classifiers(1 to 3) I need to find a way to get the number of occurences of each classifier\n",
    "#I searched up how to do this and saturncloud.io showed me the value_counts() method.\n",
    "\n",
    "counts = y[\"class\"].value_counts()\n",
    "print(counts)\n",
    "\n",
    "print(\"So wine 1 has 59 samples, wine 2 has 71 samples, and wine 3 has 48 samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {
    "id": "70e6c46f"
   },
   "source": [
    "## **Step 3:** Implement Machine Learning Model\n",
    "\n",
    "1. Import `SVC` and `DecisionTreeClassifier` from sklearn\n",
    "2. Instantiate models as `SVC()` and `DecisionTreeClassifier(max_depth = 3)`\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b2496c62-f08b-4c97-82ae-9d99041ec644",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC:\n",
      "Average Training Accuracy: 0.7037427361371023\n",
      "Average Validation Accuracy: 0.6634920634920635\n",
      "\n",
      "Decision Tree classifier:\n",
      "Average Training Accuracy: 0.9747562296858071\n",
      "Average Validation Accuracy: 0.8765079365079366\n",
      "\n",
      "  Model  Training accuracy  Validation accuracy\n",
      "0   SVC           0.703743             0.663492\n",
      "1   DTC           0.974756             0.876508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ej/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/ej/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/ej/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/ej/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/ej/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/ej/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "dtc = DecisionTreeClassifier(max_depth = 3)\n",
    "\n",
    "svc.fit(X, y)\n",
    "dtc.fit(X, y)\n",
    "\n",
    "svc_scores = cross_validate(svc, X, y, scoring='accuracy', cv=5, return_train_score=True)\n",
    "dtc_scores = cross_validate(dtc, X, y, scoring='accuracy', cv=5, return_train_score=True)\n",
    "\n",
    "\n",
    "avg_svc_train_acc = np.mean(svc_scores['train_score'])\n",
    "avg_svc_val_acc = np.mean(svc_scores['test_score'])\n",
    "\n",
    "avg_dtc_train_acc = np.mean(dtc_scores['train_score'])\n",
    "avg_dtc_val_acc = np.mean(dtc_scores['test_score'])\n",
    "\n",
    "\n",
    "print(\"SVC:\")\n",
    "print(f\"Average Training Accuracy: {avg_svc_train_acc}\")\n",
    "print(f\"Average Validation Accuracy: {avg_svc_val_acc}\\n\")\n",
    "\n",
    "print(\"Decision Tree classifier:\")\n",
    "print(f\"Average Training Accuracy: {avg_dtc_train_acc}\")\n",
    "print(f\"Average Validation Accuracy: {avg_dtc_val_acc}\\n\")\n",
    "\n",
    "results = pd.DataFrame(columns=['Model', 'Training accuracy', 'Validation accuracy'])\n",
    "results.loc[len(results)] = [\"SVC\", avg_svc_train_acc, avg_svc_val_acc]\n",
    "results.loc[len(results)] = [\"DTC\", avg_dtc_train_acc, avg_dtc_val_acc]\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870b0d2",
   "metadata": {
    "id": "0870b0d2"
   },
   "source": [
    "## **Step 4:** Validate Model\n",
    "\n",
    "Calculate the average training and validation accuracy using `cross_validate` for the two different models listed in Step 3. For this case, use `scoring='accuracy'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bbd83",
   "metadata": {
    "id": "bb0bbd83"
   },
   "source": [
    "## **Step 5:** Visualize Results (4 marks)\n",
    "\n",
    "<font color='red'>\n",
    "There is no individual mark for Steps 3 and 4 and those grades are included within the four points.\n",
    "\n",
    "</font>\n",
    "\n",
    "### **Step 5.1:** Compare Models (2 out of total 4 marks)\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4b5c0a",
   "metadata": {
    "id": "be4b5c0a"
   },
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e17878",
   "metadata": {
    "id": "f2e17878"
   },
   "source": [
    "### **Step 5.2:** Visualize Classification Errors  (2 out of total 4 marks)\n",
    "Which method gave the highest accuracy? Use this method to print the confusion matrix and classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "44b091a4",
   "metadata": {
    "id": "44b091a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 1       1.00      0.97      0.98        59\n",
      "     class 2       0.96      0.99      0.97        71\n",
      "     class 3       0.98      0.98      0.98        48\n",
      "\n",
      "    accuracy                           0.98       178\n",
      "   macro avg       0.98      0.98      0.98       178\n",
      "weighted avg       0.98      0.98      0.98       178\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: Implement best model\n",
    "# I searched up how to make a confusion matrix and got some synatx from medium.com\n",
    "#I got classification report from sklearn\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "wine_predictions = dtc.predict(X)\n",
    "cf_matrix = confusion_matrix(y, wine_predictions)\n",
    "\n",
    "sns.heatmap(cf_matrix, annot=True)\n",
    "target_names = ['class 1', 'class 2', 'class 3']\n",
    "print(classification_report(y, wine_predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d21b59",
   "metadata": {
    "id": "09d21b59"
   },
   "outputs": [],
   "source": [
    "# TO DO: Print confusion matrix using a heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef95947",
   "metadata": {
    "id": "5ef95947"
   },
   "outputs": [],
   "source": [
    "# TO DO: Print classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf319621",
   "metadata": {
    "id": "bf319621"
   },
   "source": [
    "## Questions (6 marks)\n",
    "1. How do the training and validation accuracy change depending on the method used? Explain with values.\n",
    "1. What are two reasons why the support vector machines model did not work as well as the tree-based model?\n",
    "1. How many samples were incorrectly classified in step 5.2?\n",
    "1. In this case, is maximizing precision or recall more important? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1FQstcwnXXng",
   "metadata": {
    "id": "1FQstcwnXXng"
   },
   "source": [
    "\n",
    "<font color='Green'><b>YOUR ANSWERS HERE</b></font>\n",
    "1. Both the training and validation accuracy improve drastically when the Decision Tree Classifier is used compared to the SVC. The average training accuracy for the Decision tree classifier is 97.6% compared to that of SVC which is 70.6%. The average validation accuracy for the Decision tree classifier is 86.5% compared to that of SVC which is 66.3%.\n",
    "\n",
    "2. One reason might be that using an SVC might be too complex for this dataset, since we have 13 feature vectors being used for classification. Another reason might be that since an SVC assumes a linear decision boundary by default, it might not be able to find an optimal decision boundary in this case, since the relationship between the features and target variables is not linear for this dataset.\n",
    "\n",
    "3. 2 samples actually belong to class 1 but were predicted as class 2. 1 sample actually belonged to class 2 but was predicted as class 3. 1 sample actually belonged to class 3 but was predicted as class 2. Thus, a total of 4 samples were incorrectly predicted.\n",
    "\n",
    "4. Precision reflects the ability of the model to avoid false positives. So in this case one would probably want to maximize precision so that a person does not drink the wrong wine which might have ingredients that they are allergic to for example.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ff8ae",
   "metadata": {
    "id": "664ff8ae"
   },
   "source": [
    "## Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e837da",
   "metadata": {
    "id": "d0e837da"
   },
   "source": [
    "<font color='Green'><b>DESCRIBE YOUR PROCESS HERE</b>\n",
    "\n",
    "1. The data import was sourced from the UCI Machine Learning repo. The other import statements were sourced from scikit-learn.org. The confusion matrix and heatmap functions were sourced from medium.com. The classification_report function was sourced from scikit-learn.org.\n",
    "    \n",
    "2. The steps were completed in the order they were given.\n",
    "    \n",
    "3. Prompt1: How to read a 3x3 confusion matrix properly.\n",
    "    \n",
    "I was only used to the 2x2 confusion matrices in the lecture notes so I passed prompt1 to chatgpt to gain a better understanding on how to read the 3x3 matrix.\n",
    "    \n",
    "4. I had no challenges for this part. I was just able to get a clearer understanding of how to read the confusion matrix with the help of chatgpt.\n",
    "\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd7358d",
   "metadata": {
    "id": "4cd7358d"
   },
   "source": [
    "# **Part 3: Observations/Interpretation (3 marks)**\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F3ifv218XL62",
   "metadata": {
    "id": "F3ifv218XL62"
   },
   "source": [
    "<font color='Green'><b>\n",
    "ADD YOUR FINDINGS HERE\n",
    "    \n",
    "We found that the Decision Tree Classifier would be the best model for properly classifying the samples in this dataset. This is because it produced the highest training and validation accuracy. Also the confusion matrix showed that only 4 out of 178 samples were incorrectly classified(Hence the 97% training accuracy for the DTC training set). While the three models in the first part had a high training accuracy, they had a poor validation accuracy. This might be due to the fact that overfitting occured, thus the model learned the training data too well and might have captured noise or random fluctuations in the data instead of the existing patterns.\n",
    "</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97b6ac",
   "metadata": {
    "id": "cd97b6ac"
   },
   "source": [
    "## **Part 4:** Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tDFYc89YXQGJ",
   "metadata": {
    "id": "tDFYc89YXQGJ"
   },
   "source": [
    "<font color='Green'><b>\n",
    "ADD YOUR THOUGHTS HERE\n",
    "    \n",
    "I found it interesting how the accuracy value of the DTC matched with the value we got when we used the cross_validate function. I also found it interesting how the regression models above might have learned the train data too well, causing overfitting with the test data.\n",
    "</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa21e53b",
   "metadata": {
    "id": "fa21e53b"
   },
   "source": [
    "## **Part 5:** Bonus Question (3 marks)\n",
    "\n",
    "Repeat Part 2 and compare the support vector machines model used to `LinearSVC(max_iter=5000)`. Does using `LinearSVC` improve the results? Why or why not?\n",
    "\n",
    "Is `LinearSVC` a good fit for this dataset? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fea72e",
   "metadata": {
    "id": "30fea72e"
   },
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabc68a4",
   "metadata": {
    "id": "aabc68a4"
   },
   "source": [
    "*ANSWER HERE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "241c3b12",
   "metadata": {
    "id": "241c3b12"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ej/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/ej/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/ej/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/ej/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/ej/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/ej/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/ej/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/ej/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/ej/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/ej/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/ej/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC:\n",
      "Average Training Accuracy: 0.9017531764010638\n",
      "Average Validation Accuracy: 0.8758730158730158\n",
      "\n",
      "Decision Tree classifier:\n",
      "Average Training Accuracy: 0.9747562296858071\n",
      "Average Validation Accuracy: 0.8876190476190476\n",
      "\n",
      "        Model  Training accuracy  Validation accuracy\n",
      "0  Linear SVC           0.901753             0.875873\n",
      "1         DTC           0.974756             0.887619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ej/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/ej/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/ej/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/ej/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/ej/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/ej/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/ej/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "lin_svc = LinearSVC(max_iter=5000)\n",
    "dtc = DecisionTreeClassifier(max_depth = 3)\n",
    "\n",
    "lin_svc.fit(X, y)\n",
    "dtc.fit(X, y)\n",
    "\n",
    "lin_svc_scores = cross_validate(lin_svc, X, y, scoring='accuracy', cv=5, return_train_score=True)\n",
    "dtc_scores = cross_validate(dtc, X, y, scoring='accuracy', cv=5, return_train_score=True)\n",
    "\n",
    "\n",
    "avg_lin_svc_train_acc = np.mean(lin_svc_scores['train_score'])\n",
    "avg_lin_svc_val_acc = np.mean(lin_svc_scores['test_score'])\n",
    "\n",
    "avg_dtc_train_acc = np.mean(dtc_scores['train_score'])\n",
    "avg_dtc_val_acc = np.mean(dtc_scores['test_score'])\n",
    "\n",
    "\n",
    "print(\"LinearSVC:\")\n",
    "print(f\"Average Training Accuracy: {avg_lin_svc_train_acc}\")\n",
    "print(f\"Average Validation Accuracy: {avg_lin_svc_val_acc}\\n\")\n",
    "\n",
    "print(\"Decision Tree classifier:\")\n",
    "print(f\"Average Training Accuracy: {avg_dtc_train_acc}\")\n",
    "print(f\"Average Validation Accuracy: {avg_dtc_val_acc}\\n\")\n",
    "\n",
    "results = pd.DataFrame(columns=['Model', 'Training accuracy', 'Validation accuracy'])\n",
    "results.loc[len(results)] = [\"Linear SVC\", avg_lin_svc_train_acc, avg_lin_svc_val_acc]\n",
    "results.loc[len(results)] = [\"DTC\", avg_dtc_train_acc, avg_dtc_val_acc]\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d6c7d3-f808-40d6-b007-521c498801a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Using LinearSVC is often more scalable than SVC with a linear kernel, particularly for high-dimensional datasets. It can handle large numbers of features more efficiently because it does not need to compute the kernel matrix.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
